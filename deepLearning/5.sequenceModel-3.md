# 序列模型（3）

## 序列模型和注意力机制（Sequence models & Attention mechanism）

[上一章](5.sequenceModel-2.md) --- [下一章](6.fewShotLearning.md)

---

# 序列模型和注意力机制

## 注意力机制

**通俗解释**: 关注序列中重要部分。重点：提升RNN性能。

## 注意力机制的基本思想

**通俗解释**: 为每个输出加权输入。重点：动态权重。

## 注意力权重计算

**通俗解释**: 用查询和键计算权重。重点：softmax归一。

**数学公式**:
$$
\alpha_i = \frac{\exp(e_i)}{\sum \exp(e_j)}
$$

## 自注意力机制

**通俗解释**: 输入自己关注自己。重点：Transformer核心。

## Transformer模型

**通俗解释**: 全注意力网络，取代RNN。重点：并行高效。

## 多头注意力

**通俗解释**: 多组注意力并行。重点：捕捉多方面关系。

## Transformer的编码器和解码器

**通俗解释**: 编码输入，解码输出。重点：序列转换。

## 注意力机制的可视化

**通俗解释**: 显示关注重点。重点：解释模型。

## 序列模型的应用

**通俗解释**: 机器翻译、语音识别。重点：广泛适用。

## 参考文献

**通俗解释**: 查阅Vaswani的Transformer。重点：技术细节。