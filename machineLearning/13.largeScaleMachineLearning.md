# 大规模机器学习

[上一章](12.recommendedSystem.md) --- [下一章](14.applicationOCR.md)

---

**通俗解释**: 大数据提升模型性能。重点：需高效算法。

## 确认大规模的训练集是否必要

**通俗解释**: 学习曲线判断。重点：高偏差时无需更多数据。

## 随机梯度下降法 Stochastic Gradient Descent (SGD)

**通俗解释**: 逐样本更新权重。重点：快但噪声大。

## 小批量梯度下降 Mini-Batch Gradient Descent

**通俗解释**: 批次更新，平衡速度与稳定。重点：调批大小。

## 随机梯度下降收敛

**通俗解释**: 监控平均损失。重点：学习率衰减。

## 在线学习 Online Learning

**通俗解释**: 实时更新模型。重点：适应动态数据。

## MapReduce和数据并行

**通俗解释**: 分布式计算分块处理。重点：加速大模型。